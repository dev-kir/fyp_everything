[0;32m========================================[0m
[0;32mSwarmGuard Scenario 2 - Ultimate Test[0m
[0;32m========================================[0m

[0;34mConfiguration:[0m
  Alpine nodes:       5
  Users per Alpine:   15
  Total users:        75
  Stagger delay:      2s (between user starts)
  Ramp time:          60s (per user, 0â†’max)
  Hold time:          900s (maintain peak load)

[0;34mPer-User Resource Contribution:[0m
  CPU:     2%
  Memory:  8MB
  Network: 12Mbps

[0;34mExpected Peak Load (All Users Active):[0m
  Total CPU:     150% \033[1;33m(Scenario 2 threshold: 75%)\033[0m
  Total Memory:  600MB \033[1;33m(Scenario 2 threshold: 80% node memory)\033[0m
  Total Network: 900Mbps \033[1;33m(Scenario 2 threshold: 65Mbps)\033[0m

[0;34mTimeline:[0m
  T+0s:      User 1 starts on each Alpine (4 users total)
  T+2s:     User 2 starts on each Alpine (8 users total)
  T+88s:  All 75 users active, ramping complete
  T+??s:     Scenario 2 triggers â†’ Scale 1 â†’ 2+ replicas
  T+988s:  Test completes, resources release
  T+1168s: Scale-down cooldown â†’ Back to 1 replica

[1;33m[0/5] Pre-cleanup: Killing any leftover processes...[0m
[0;32mâœ“ Pre-cleanup complete[0m

[1;33m[1/5] Checking initial state...[0m
  Current web-stress replicas: 1

[1;33m[2/5] Checking service health...[0m
[0;32mâœ“ Service healthy[0m

[1;33m[3/5] Creating Alpine simulation script...[0m
[0;32mâœ“ Script created[0m

[1;33m[4/5] Deploying to Alpine nodes...[0m
  Deploying to alpine-1...
  Deploying to alpine-2...
  Deploying to alpine-3...
  Deploying to alpine-4...
  Deploying to alpine-5...
[0;32mâœ“ Deployed to 5 Alpine nodes[0m

[0;32m========================================[0m
[0;32m[5/5] Starting Scenario 2 Test[0m
[0;32m========================================[0m

[1;33mğŸ“Š OPEN GRAFANA NOW:[0m
   [0;34mhttp://192.168.2.61:3000[0m
   Dashboard: [0;34mSwarmGuard_All_Sum[0m

[1;33mExpected Behavior:[0m
  Phase 1: Gradual resource ramp-up (88s)
    - CPU, Memory, Network all increase smoothly
    - Each user adds load in staggered fashion

  Phase 2: Scenario 2 triggers (around T+60-90s)
    - Recovery manager detects: CPU > 75% AND Network > 65Mbps
    - Scales web-stress: 1 â†’ 2 replicas

  Phase 3: Load distribution visible in Grafana
    - Before: 1 replica at ~150% CPU, ~600MB RAM
    - After:  2 replicas at ~75% CPU each, ~300MB RAM each
    - LB Dashboard shows requests distributed across both replicas

  Phase 4: Hold peak load (900s)
    - Maintain distributed load to show stability

  Phase 5: Cool down and scale-down
    - After test completes, resources release
    - Recovery manager waits 180s cooldown
    - Scales back: 2 â†’ 1 replica

[1;33mPress Ctrl+C to stop early[0m

[0;34m  Starting 15 users on alpine-1...[0m
[0;34m  Starting 15 users on alpine-2...[0m
[0;34m  Starting 15 users on alpine-3...[0m
[0;34m  Starting 15 users on alpine-4...[0m
[0;34m  Starting 15 users on alpine-5...[0m

[0;32mâœ“ 75 users triggered across 5 Alpine nodes[0m

[1;33mMonitoring for 988s...[0m

[T+10s] Ramping... | Active users: ~30/75 | Replicas: 1
[T+20s] Ramping... | Active users: ~55/75 | Replicas: 1
[T+30s] Ramping... | Active users: ~75/75 | Replicas: 1
[T+41s] Ramping... | Active users: ~75/75 | Replicas: 1
[T+51s] Ramping... | Active users: ~75/75 | Replicas: 1
[T+61s] Ramping... | Active users: ~75/75 | Replicas: 1
[T+71s] Ramping... | Active users: ~75/75 | Replicas: 1
[T+81s] Ramping... | Active users: ~75/75 | Replicas: 1
[T+91s] Peak load | Replicas: 1 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+102s
  Change:    1 â†’ 2 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~75% CPU
    - Each replica now handles ~300MB Memory
    - Each replica now handles ~450Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+112s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+122s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+132s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+142s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+153s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+163s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+173s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+183s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+193s] Peak load | Replicas: 2 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+204s
  Change:    2 â†’ 3 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~50% CPU
    - Each replica now handles ~200MB Memory
    - Each replica now handles ~300Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+214s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+224s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+234s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+244s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+255s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+265s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+275s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+285s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+295s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+306s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+316s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+326s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+336s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+346s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+357s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+367s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+377s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+387s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+397s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+408s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+418s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+428s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+438s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+448s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+459s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+469s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+479s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+489s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+499s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+510s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+520s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+530s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+540s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+550s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+561s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+571s] Peak load | Replicas: 3 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+581s
  Change:    3 â†’ 2 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~75% CPU
    - Each replica now handles ~300MB Memory
    - Each replica now handles ~450Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+591s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+601s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+612s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+622s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+632s] Peak load | Replicas: 2 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+642s
  Change:    2 â†’ 3 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~50% CPU
    - Each replica now handles ~200MB Memory
    - Each replica now handles ~300Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+652s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+663s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+673s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+683s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+693s] Peak load | Replicas: 3 | Monitoring for scale events...

[1;33m[Cleanup] Stopping all Alpine traffic...[0m
[1;33m[Cleanup] Stopping stress on containers...[0m
[0;32mâœ“ Cleanup complete[0m
[T+753s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+763s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+773s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+783s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+793s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+804s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+814s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+824s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+834s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+844s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+855s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+865s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+875s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+885s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+896s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+906s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+916s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+926s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+937s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+947s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+957s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+967s] Peak load | Replicas: 3 | Monitoring for scale events...
[T+978s] Peak load | Replicas: 3 | Monitoring for scale events...

[1;33mWaiting for Alpine nodes to complete...[0m

[0;32m========================================[0m
[0;32mTest Complete![0m
[0;32m========================================[0m

[0;34mSummary:[0m
  Initial replicas:  1
  Final replicas:    3
  Total users:       75
  Expected peak:     150% CPU, 600MB RAM, 900Mbps NET
  Scale-up time:     T+642s

[0;34mCurrent replica distribution:[0m
NAME           NODE       CURRENT STATE
web-stress.1   worker-3   Running 14 minutes ago
web-stress.2   worker-1   Running 14 minutes ago
web-stress.3   worker-4   Running 5 minutes ago

[0;34mLoad Balancer Metrics:[0m
{
  "total_requests": 25755,
  "healthy_replicas": 3,
  "algorithm": "lease",
  "distribution": [
    {
      "node": "worker-1",
      "requests": 1580,
      "leases": 0
    },
    {
      "node": "worker-4",
      "requests": 354,
      "leases": 0
    },
    {
      "node": "worker-3",
      "requests": 1426,
      "leases": 0
    }
  ]
}

[0;34mAlpine Node Summary:[0m
  [alpine-1]
    Killed
    Killed
    Killed
  [alpine-2]
      [alpine-2] User 15: starting continuous traffic (T+28s)
    Killed
    Killed
  [alpine-3]
      [alpine-3] User 14: starting continuous traffic (T+26s)
      [alpine-3] User 15: starting continuous traffic (T+28s)
    Killed
  [alpine-4]
    Killed
    Killed
    Killed
  [alpine-5]
    Killed
    Killed
    Killed

[0;32mâœ… Scenario 2 Ultimate Test Complete![0m

[1;33mNext Steps:[0m
  1. Review Grafana dashboards:
     - SwarmGuard_All_Sum: Overall CPU/Memory/Network distribution
     - SwarmGuard Load Balancer Visualization: Request distribution

  2. Wait ~3-4 minutes for scale-down cooldown
     - Recovery manager will scale back to 1 replica when idle

  3. Try different configurations:
     ./scenario2_ultimate.sh 15 4 40 4 2 15 240   # Faster ramp
     ./scenario2_ultimate.sh 8 7 70 7 4 25 300    # Higher load per user

  4. Check recovery manager logs:
     ssh master 'docker service logs recovery-manager --tail 50'


[1;33m[Cleanup] Stopping all Alpine traffic...[0m
[1;33m[Cleanup] Stopping stress on containers...[0m
[0;32mâœ“ Cleanup complete[0m
