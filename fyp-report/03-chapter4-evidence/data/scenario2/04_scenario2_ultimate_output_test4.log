[0;32m========================================[0m
[0;32mSwarmGuard Scenario 2 - Ultimate Test[0m
[0;32m========================================[0m

[0;34mConfiguration:[0m
  Alpine nodes:       5
  Users per Alpine:   12
  Total users:        60
  Stagger delay:      2s (between user starts)
  Ramp time:          60s (per user, 0â†’max)
  Hold time:          900s (maintain peak load)

[0;34mPer-User Resource Contribution:[0m
  CPU:     2%
  Memory:  8MB
  Network: 12Mbps

[0;34mExpected Peak Load (All Users Active):[0m
  Total CPU:     120% \033[1;33m(Scenario 2 threshold: 75%)\033[0m
  Total Memory:  480MB \033[1;33m(Scenario 2 threshold: 80% node memory)\033[0m
  Total Network: 720Mbps \033[1;33m(Scenario 2 threshold: 65Mbps)\033[0m

[0;34mTimeline:[0m
  T+0s:      User 1 starts on each Alpine (4 users total)
  T+2s:     User 2 starts on each Alpine (8 users total)
  T+82s:  All 60 users active, ramping complete
  T+??s:     Scenario 2 triggers â†’ Scale 1 â†’ 2+ replicas
  T+982s:  Test completes, resources release
  T+1162s: Scale-down cooldown â†’ Back to 1 replica

[1;33m[0/5] Pre-cleanup: Killing any leftover processes...[0m
[0;32mâœ“ Pre-cleanup complete[0m

[1;33m[1/5] Checking initial state...[0m
  Current web-stress replicas: 1

[1;33m[2/5] Checking service health...[0m
[0;32mâœ“ Service healthy[0m

[1;33m[3/5] Creating Alpine simulation script...[0m
[0;32mâœ“ Script created[0m

[1;33m[4/5] Deploying to Alpine nodes...[0m
  Deploying to alpine-1...
  Deploying to alpine-2...
  Deploying to alpine-3...
  Deploying to alpine-4...
  Deploying to alpine-5...
[0;32mâœ“ Deployed to 5 Alpine nodes[0m

[0;32m========================================[0m
[0;32m[5/5] Starting Scenario 2 Test[0m
[0;32m========================================[0m

[1;33mğŸ“Š OPEN GRAFANA NOW:[0m
   [0;34mhttp://192.168.2.61:3000[0m
   Dashboard: [0;34mSwarmGuard_All_Sum[0m

[1;33mExpected Behavior:[0m
  Phase 1: Gradual resource ramp-up (82s)
    - CPU, Memory, Network all increase smoothly
    - Each user adds load in staggered fashion

  Phase 2: Scenario 2 triggers (around T+60-90s)
    - Recovery manager detects: CPU > 75% AND Network > 65Mbps
    - Scales web-stress: 1 â†’ 2 replicas

  Phase 3: Load distribution visible in Grafana
    - Before: 1 replica at ~120% CPU, ~480MB RAM
    - After:  2 replicas at ~60% CPU each, ~240MB RAM each
    - LB Dashboard shows requests distributed across both replicas

  Phase 4: Hold peak load (900s)
    - Maintain distributed load to show stability

  Phase 5: Cool down and scale-down
    - After test completes, resources release
    - Recovery manager waits 180s cooldown
    - Scales back: 2 â†’ 1 replica

[1;33mPress Ctrl+C to stop early[0m

[0;34m  Starting 12 users on alpine-1...[0m
[0;34m  Starting 12 users on alpine-2...[0m
[0;34m  Starting 12 users on alpine-3...[0m
[0;34m  Starting 12 users on alpine-4...[0m
[0;34m  Starting 12 users on alpine-5...[0m

[0;32mâœ“ 60 users triggered across 5 Alpine nodes[0m

[1;33mMonitoring for 982s...[0m

[T+10s] Ramping... | Active users: ~30/60 | Replicas: 1
[T+20s] Ramping... | Active users: ~55/60 | Replicas: 1
[T+30s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+40s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+51s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+61s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+71s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+81s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+91s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+101s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+112s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+122s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+132s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+142s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+152s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+163s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+173s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+183s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+193s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+203s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+214s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+224s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+234s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+244s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+254s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+264s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+275s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+285s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+295s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+306s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+316s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+326s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+337s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+347s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+357s] Peak load | Replicas: 1 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+367s
  Change:    1 â†’ 2 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~60% CPU
    - Each replica now handles ~240MB Memory
    - Each replica now handles ~360Mbps Network

[1;33m  Check Grafana to verify distribution![0m


[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+378s
  Change:    2 â†’ 1 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~120% CPU
    - Each replica now handles ~480MB Memory
    - Each replica now handles ~720Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+388s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+398s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+408s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+419s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+429s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+439s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+449s] Peak load | Replicas: 1 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+460s
  Change:    1 â†’ 3 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~40% CPU
    - Each replica now handles ~160MB Memory
    - Each replica now handles ~240Mbps Network

[1;33m  Check Grafana to verify distribution![0m


[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+470s
  Change:    3 â†’ 2 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~60% CPU
    - Each replica now handles ~240MB Memory
    - Each replica now handles ~360Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+480s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+490s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+500s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+511s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+521s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+531s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+542s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+552s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+562s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+572s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+582s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+592s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+603s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+613s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+623s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+633s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+643s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+654s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+664s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+674s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+684s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+694s] Peak load | Replicas: 2 | Monitoring for scale events...

[1;33m[Cleanup] Stopping all Alpine traffic...[0m
[1;33m[Cleanup] Stopping stress on containers...[0m
[0;32mâœ“ Cleanup complete[0m
[T+755s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+765s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+775s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+785s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+795s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+806s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+816s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+826s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+836s] Peak load | Replicas: 2 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+846s
  Change:    2 â†’ 1 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~120% CPU
    - Each replica now handles ~480MB Memory
    - Each replica now handles ~720Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+857s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+867s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+877s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+887s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+897s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+908s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+918s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+928s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+938s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+948s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+959s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+969s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+979s] Peak load | Replicas: 1 | Monitoring for scale events...

[1;33mWaiting for Alpine nodes to complete...[0m

[0;32m========================================[0m
[0;32mTest Complete![0m
[0;32m========================================[0m

[0;34mSummary:[0m
  Initial replicas:  1
  Final replicas:    1
  Total users:       60
  Expected peak:     120% CPU, 480MB RAM, 720Mbps NET
  Scale-up time:     T+846s

[0;34mCurrent replica distribution:[0m
NAME           NODE       CURRENT STATE
web-stress.1   worker-2   Running 8 minutes ago

[0;34mLoad Balancer Metrics:[0m
{
  "total_requests": 41934,
  "healthy_replicas": 1,
  "algorithm": "lease",
  "distribution": [
    {
      "node": "worker-2",
      "requests": 757,
      "leases": 0
    }
  ]
}

[0;34mAlpine Node Summary:[0m
  [alpine-1]
    Killed
    Killed
    Killed
  [alpine-2]
    Killed
    Killed
    Killed
  [alpine-3]
      [alpine-3] User 10: starting continuous traffic (T+18s)
      [alpine-3] User 11: starting continuous traffic (T+20s)
      [alpine-3] User 12: starting continuous traffic (T+22s)
  [alpine-4]
    Killed
    Killed
    Killed
  [alpine-5]
    Killed
    Killed
    Killed

[0;32mâœ… Scenario 2 Ultimate Test Complete![0m

[1;33mNext Steps:[0m
  1. Review Grafana dashboards:
     - SwarmGuard_All_Sum: Overall CPU/Memory/Network distribution
     - SwarmGuard Load Balancer Visualization: Request distribution

  2. Wait ~3-4 minutes for scale-down cooldown
     - Recovery manager will scale back to 1 replica when idle

  3. Try different configurations:
     ./scenario2_ultimate.sh 15 4 40 4 2 15 240   # Faster ramp
     ./scenario2_ultimate.sh 8 7 70 7 4 25 300    # Higher load per user

  4. Check recovery manager logs:
     ssh master 'docker service logs recovery-manager --tail 50'


[1;33m[Cleanup] Stopping all Alpine traffic...[0m
[1;33m[Cleanup] Stopping stress on containers...[0m
[0;32mâœ“ Cleanup complete[0m
