[0;32m========================================[0m
[0;32mSwarmGuard Scenario 2 - Ultimate Test[0m
[0;32m========================================[0m

[0;34mConfiguration:[0m
  Alpine nodes:       5
  Users per Alpine:   12
  Total users:        60
  Stagger delay:      2s (between user starts)
  Ramp time:          60s (per user, 0â†’max)
  Hold time:          900s (maintain peak load)

[0;34mPer-User Resource Contribution:[0m
  CPU:     2%
  Memory:  8MB
  Network: 12Mbps

[0;34mExpected Peak Load (All Users Active):[0m
  Total CPU:     120% \033[1;33m(Scenario 2 threshold: 75%)\033[0m
  Total Memory:  480MB \033[1;33m(Scenario 2 threshold: 80% node memory)\033[0m
  Total Network: 720Mbps \033[1;33m(Scenario 2 threshold: 65Mbps)\033[0m

[0;34mTimeline:[0m
  T+0s:      User 1 starts on each Alpine (4 users total)
  T+2s:     User 2 starts on each Alpine (8 users total)
  T+82s:  All 60 users active, ramping complete
  T+??s:     Scenario 2 triggers â†’ Scale 1 â†’ 2+ replicas
  T+982s:  Test completes, resources release
  T+1162s: Scale-down cooldown â†’ Back to 1 replica

[1;33m[0/5] Pre-cleanup: Killing any leftover processes...[0m
[0;32mâœ“ Pre-cleanup complete[0m

[1;33m[1/5] Checking initial state...[0m
  Current web-stress replicas: 1

[1;33m[2/5] Checking service health...[0m
[0;32mâœ“ Service healthy[0m

[1;33m[3/5] Creating Alpine simulation script...[0m
[0;32mâœ“ Script created[0m

[1;33m[4/5] Deploying to Alpine nodes...[0m
  Deploying to alpine-1...
  Deploying to alpine-2...
  Deploying to alpine-3...
  Deploying to alpine-4...
  Deploying to alpine-5...
[0;32mâœ“ Deployed to 5 Alpine nodes[0m

[0;32m========================================[0m
[0;32m[5/5] Starting Scenario 2 Test[0m
[0;32m========================================[0m

[1;33mğŸ“Š OPEN GRAFANA NOW:[0m
   [0;34mhttp://192.168.2.61:3000[0m
   Dashboard: [0;34mSwarmGuard_All_Sum[0m

[1;33mExpected Behavior:[0m
  Phase 1: Gradual resource ramp-up (82s)
    - CPU, Memory, Network all increase smoothly
    - Each user adds load in staggered fashion

  Phase 2: Scenario 2 triggers (around T+60-90s)
    - Recovery manager detects: CPU > 75% AND Network > 65Mbps
    - Scales web-stress: 1 â†’ 2 replicas

  Phase 3: Load distribution visible in Grafana
    - Before: 1 replica at ~120% CPU, ~480MB RAM
    - After:  2 replicas at ~60% CPU each, ~240MB RAM each
    - LB Dashboard shows requests distributed across both replicas

  Phase 4: Hold peak load (900s)
    - Maintain distributed load to show stability

  Phase 5: Cool down and scale-down
    - After test completes, resources release
    - Recovery manager waits 180s cooldown
    - Scales back: 2 â†’ 1 replica

[1;33mPress Ctrl+C to stop early[0m

[0;34m  Starting 12 users on alpine-1...[0m
[0;34m  Starting 12 users on alpine-2...[0m
[0;34m  Starting 12 users on alpine-3...[0m
[0;34m  Starting 12 users on alpine-4...[0m
[0;34m  Starting 12 users on alpine-5...[0m

[0;32mâœ“ 60 users triggered across 5 Alpine nodes[0m

[1;33mMonitoring for 982s...[0m

[T+10s] Ramping... | Active users: ~30/60 | Replicas: 1
[T+20s] Ramping... | Active users: ~55/60 | Replicas: 1
[T+30s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+40s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+51s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+61s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+71s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+81s] Ramping... | Active users: ~60/60 | Replicas: 1
[T+91s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+102s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+112s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+122s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+132s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+142s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+153s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+163s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+173s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+183s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+193s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+204s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+214s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+224s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+234s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+244s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+255s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+265s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+275s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+285s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+296s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+306s] Peak load | Replicas: 1 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+316s
  Change:    1 â†’ 2 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~60% CPU
    - Each replica now handles ~240MB Memory
    - Each replica now handles ~360Mbps Network

[1;33m  Check Grafana to verify distribution![0m


[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+326s
  Change:    2 â†’ 1 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~120% CPU
    - Each replica now handles ~480MB Memory
    - Each replica now handles ~720Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+336s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+347s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+357s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+367s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+377s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+388s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+398s] Peak load | Replicas: 1 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+408s
  Change:    1 â†’ 3 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~40% CPU
    - Each replica now handles ~160MB Memory
    - Each replica now handles ~240Mbps Network

[1;33m  Check Grafana to verify distribution![0m


[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+419s
  Change:    3 â†’ 2 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~60% CPU
    - Each replica now handles ~240MB Memory
    - Each replica now handles ~360Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+429s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+439s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+449s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+459s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+470s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+480s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+490s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+500s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+511s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+521s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+531s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+541s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+551s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+562s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+572s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+582s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+592s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+602s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+613s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+623s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+633s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+643s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+653s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+664s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+674s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+684s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+694s] Peak load | Replicas: 2 | Monitoring for scale events...

[1;33m[Cleanup] Stopping all Alpine traffic...[0m
[1;33m[Cleanup] Stopping stress on containers...[0m
[0;32mâœ“ Cleanup complete[0m
[T+748s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+758s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+769s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+779s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+789s] Peak load | Replicas: 2 | Monitoring for scale events...
[T+799s] Peak load | Replicas: 2 | Monitoring for scale events...

[0;32mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—[0m
[0;32mâ•‘  âœ… SCALE EVENT DETECTED!                              â•‘[0m
[0;32mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[0m
  Time:      T+809s
  Change:    2 â†’ 1 replicas

[1;33m  Expected load distribution:[0m
    - Each replica now handles ~120% CPU
    - Each replica now handles ~480MB Memory
    - Each replica now handles ~720Mbps Network

[1;33m  Check Grafana to verify distribution![0m

[T+820s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+830s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+840s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+850s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+860s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+871s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+881s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+891s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+901s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+911s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+922s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+932s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+942s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+952s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+963s] Peak load | Replicas: 1 | Monitoring for scale events...
[T+973s] Peak load | Replicas: 1 | Monitoring for scale events...

[1;33mWaiting for Alpine nodes to complete...[0m

[0;32m========================================[0m
[0;32mTest Complete![0m
[0;32m========================================[0m

[0;34mSummary:[0m
  Initial replicas:  1
  Final replicas:    1
  Total users:       60
  Expected peak:     120% CPU, 480MB RAM, 720Mbps NET
  Scale-up time:     T+809s

[0;34mCurrent replica distribution:[0m
NAME           NODE       CURRENT STATE
web-stress.1   worker-4   Running 9 minutes ago

[0;34mLoad Balancer Metrics:[0m
{
  "total_requests": 63699,
  "healthy_replicas": 1,
  "algorithm": "lease",
  "distribution": [
    {
      "node": "worker-4",
      "requests": 903,
      "leases": 0
    }
  ]
}

[0;34mAlpine Node Summary:[0m
  [alpine-1]
    Killed
    Killed
    Killed
  [alpine-2]
      [alpine-2] User 10: starting continuous traffic (T+18s)
      [alpine-2] User 11: starting continuous traffic (T+20s)
      [alpine-2] User 12: starting continuous traffic (T+22s)
  [alpine-3]
    Killed
    Killed
    Killed
  [alpine-4]
    Killed
    Killed
    Killed
  [alpine-5]
    wget: server returned error: HTTP/1.1 502 Bad Gateway
    Killed
    Killed

[0;32mâœ… Scenario 2 Ultimate Test Complete![0m

[1;33mNext Steps:[0m
  1. Review Grafana dashboards:
     - SwarmGuard_All_Sum: Overall CPU/Memory/Network distribution
     - SwarmGuard Load Balancer Visualization: Request distribution

  2. Wait ~3-4 minutes for scale-down cooldown
     - Recovery manager will scale back to 1 replica when idle

  3. Try different configurations:
     ./scenario2_ultimate.sh 15 4 40 4 2 15 240   # Faster ramp
     ./scenario2_ultimate.sh 8 7 70 7 4 25 300    # Higher load per user

  4. Check recovery manager logs:
     ssh master 'docker service logs recovery-manager --tail 50'


[1;33m[Cleanup] Stopping all Alpine traffic...[0m
[1;33m[Cleanup] Stopping stress on containers...[0m
[0;32mâœ“ Cleanup complete[0m
